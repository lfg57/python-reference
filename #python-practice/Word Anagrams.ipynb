{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Anagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to **find anagrams in the dictionary of English words**. Two words are anagrams of each other if their letters can be rearranged to turn one word into the other. For example, \"$\\texttt{listen}$\" and \"$\\texttt{silent}$\" are anagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals:**\n",
    "\n",
    "1. Load a list of English words into a Python list.\n",
    "2. Create a Python dictionary of anagrams, indexed by anagrammed word.\n",
    "3. Group dictionary words by their length and then find the total number of anagrams in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the English Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading a list of English words into Python. The data file is called `web2` and it should be located in the `../data/` folder. The file contains a list of words from *Webster's Second International Dictionary (1934)*. The 1934 copyright has lapsed and this file is included in Unix and OS X at `/usr/share/dict/web2)` as a reference word list for various uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and read in the data located at the specified path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '#python-practice/data/web2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    }
   ],
   "source": [
    "words = open(data_path, 'r').readlines()\n",
    "words = [line.rstrip() for line in words]  # Remove '\\n'\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same in just one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'Aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'Aaron']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [line.rstrip() for line in open(data_path, 'r')]\n",
    "\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also convert all the words to lowercase since we don't need capitalized words in anagrams. We can open the file, read in its contents, remove newline characters, and change case in just one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [line.rstrip().lower() for line in open(data_path, 'r')]\n",
    "\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the word list has duplicates, such as the terms 'A' and 'a' which now both appear as 'a' after changing the terms to lowercase. To remove duplicates, convert the list to a set and then convert back to a list. In this process, the set conversion loses the alphabetical ordering of the terms, so we also need to sort the resulting list of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_unique = sorted(list(set(words)))\n",
    "\n",
    "print(len(words_unique))\n",
    "words_unique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can open the file, read in its contents, remove newline characters, change the terms to lowercase, and remove duplicates *in a single step*:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_unique = sorted(list(set([line.rstrip().lower() for line in open(data_path, 'r')])))\n",
    "\n",
    "print(len(words_unique))\n",
    "words_unique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can write a nice function** to accomplish the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "def get_data(data_path):\n",
    "    \"\"\"\n",
    "    Returns a clean, sorted list of unique lowercase English words read in from\n",
    "    the given data file located at the given path.\n",
    "    \"\"\"\n",
    "    return sorted(list(set([line.rstrip().lower()\n",
    "                            for line in open(data_path, 'r')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = get_data(data_path)\n",
    "\n",
    "print(len(wordlist))\n",
    "wordlist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Anagrams by Word Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two words are anagrams of each other if their letters can be rearranged to turn one word into the other. For example, \"$\\texttt{listen}$\" and \"$\\texttt{silent}$\" are anagrams. Since anagrams have the same letters, just in different order, we can take advantage of the `sorted()` function and the `join()` string method to define a **word signature**. This way, **two words are anagrams of each other *if they have the same signature***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sorted(word)` returns a sorted list of individual word characters. Hence, two words are anagrams if `sorted(word1) == sorted(word2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'i', 'l', 'n', 's', 't']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('listen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('listen') == sorted ('silent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `''.join()` to join the individual characters and create the signature. We write a function to do it all in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "def signature(word):\n",
    "    \"\"\"\n",
    "    Returns the signature of a given word, where the signature is an ordered\n",
    "    arrangement of the individual characters of the word, joined to create a\n",
    "    single string.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ''.join(sorted(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that \"$\\texttt{listen}$\" and \"$\\texttt{silent}$\" have the same signature, namely \"$\\texttt{eilnst}$\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eilnst\n",
      "eilnst\n"
     ]
    }
   ],
   "source": [
    "print(signature('listen'))\n",
    "print(signature('silent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our *first approach* to finding anagrams of a given word is to go through the entire list of English words, comparing the signature of the given word against the signature of every other word in the list. This approach should not be very fast because sorting the letters of every word when creating the signature is an expensive operation $-$ `O(n log n)`. We can use the Jupyter magic `%timeit` to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "def anagrams_slow(given_word):\n",
    "    return [word for word in wordlist \n",
    "            if signature(given_word) == signature(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enlist', 'listen', 'silent', 'tinsel']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams_slow('listen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 ms ± 46.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_slow('listen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a signature is an expensive operation that we keep repeating for every word in the dictionary. We need a faster way to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much better approach is to create a Python dictionary of all the words indexed by their signatures. Every item in the dictionary will have a signature as the key and a list of words as the value. This way, getting the anagrams of a given word would be as simple as looking up the dictionary entry for the signature of the word and getting the list of values. This approach is `O(n)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use a `default dict` object from the Collections module and the `append()` method to create a dictionary containing lists as values. This helps us provide a default value, in this case an empty list, to avoid a `KeyError` when you try to get a key that does not exist. For example, we get an error before the first time that we try to add the word \"$\\texttt{a}$\" to the corresponding signature, which in this case is also \"$\\texttt{a}$\", since the dictionary key (signature) does not exist yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following simple example illustrates what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {}\n",
    "mydict['a'] = '1'\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'b'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['a'] = 'b'\n",
    "mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that simple value assignment to a key does not work for our purpose, since every time we add a value for a given key, the previous value is replaced by the new one. To keep adding values to a list for a given key, we need to use the `append()` list method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2af8295be777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmydict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "mydict = {}\n",
    "mydict['a'].append('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we get a `KeyError`, as previously stated. So, we use `defaultdict` instead to initialize the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'a': ['1']})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = collections.defaultdict(list)  # as opposed to mydict = {}\n",
    "mydict['a'].append('1')\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'a': ['1', 'b']})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['a'].append('b')\n",
    "mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see what the situation is, we can apply this to our problem. Summarizing:\n",
    "\n",
    "- Create an empty dictionary using `defaultdict`.\n",
    "- Loop over all words in the English word list.\n",
    "- Find the signature of every word, make it a key, and append the word to a list of values for the key. The value for every key (signature) becomes a list of all the words that have the same signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# =============================================================================\n",
    "def anagrams_fast(word):\n",
    "    \"\"\"\n",
    "    Finds the signature of the given word and returns a list of all the\n",
    "    anagrams for that word by a simple O(1) dictionary lookup.\n",
    "    \"\"\"\n",
    "    return words_bysignature[signature(word)]\n",
    "\n",
    "# Buld a dictionary of words indexed by signature, where the key is the \n",
    "# signature of every word in the clean list of English words (wordlist)\n",
    "# and the value is a list of all words that share the same signature.\n",
    "words_bysignature = collections.defaultdict(list)\n",
    "for word in wordlist:\n",
    "    words_bysignature[signature(word)].append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now **find anagrams by a simple dictionary lookup**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enlist', 'listen', 'silent', 'tinsel']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams_fast('listen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we time both solutions, we see how much faster the second solution is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 ms ± 6.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_slow('listen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 ns ± 5.11 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_fast('listen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can **get all the anagrams in the list of English words**, excluding the trivial ones, where a word is an anagram of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagrams_wordlist = {word:anagrams_fast(word) for word in wordlist if len(anagrams_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 ms ± 3.63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_wordlist = {word:anagrams_fast(word) for word in wordlist if len(anagrams_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the time it takes to *find the anagrams of a single word using Approach 1* is approximately equal to the time it takes to *find the anagrams of the entire list of English words using Approach 2*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that about 14% of the words in the English dictionary have anagrams that are not trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32890"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anagrams_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.03%\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2f}%\".format(len(anagrams_wordlist) / len(wordlist) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enlist', 'listen', 'silent', 'tinsel']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# =============================================================================\n",
    "def get_wordlist(data_path):\n",
    "    \"\"\"\n",
    "    Returns a clean, sorted list of unique lowercase English words read in from\n",
    "    the given data file located at the given path.\n",
    "    \"\"\"\n",
    "    return sorted(list(set([line.rstrip().lower()\n",
    "                            for line in open(data_path, 'r')])))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def signature(word):\n",
    "    \"\"\"\n",
    "    Returns the signature of a given word, where the signature is an ordered\n",
    "    arrangement of the individual characters of the word, joined to create a\n",
    "    single string.\n",
    "    \"\"\"\n",
    "    return ''.join(sorted(word))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def anagrams_fast(word):\n",
    "    \"\"\"\n",
    "    Finds the signature of the given word and returns a list of all the\n",
    "    anagrams for that word by a simple O(1) dictionary lookup.\n",
    "    \"\"\"\n",
    "    return words_bysignature[signature(word)]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # main()\n",
    "    \n",
    "    # Set the path for the source list of English words.\n",
    "    data_path = '#python-practice/data/web2'\n",
    "\n",
    "    # Get a clean, sorted version of unique lowercase English words.\n",
    "    wordlist = get_data(data_path)\n",
    "\n",
    "    # Buld a dictionary of words indexed by signature, where the key is the \n",
    "    # signature of every word in the clean list of English words (wordlist)\n",
    "    # and the value is a list of all the words that share the same signature.\n",
    "    words_bysignature = collections.defaultdict(list)\n",
    "\n",
    "    for word in wordlist:\n",
    "        words_bysignature[signature(word)].append(word)\n",
    "\n",
    "    # Find anagrams of a given word by a simple dictionary lookup.\n",
    "    word = 'listen'\n",
    "    print(anagrams_fast(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Anagrams by Word Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge Goals:**\n",
    "\n",
    "- Given a list of words from a data file, separate words into classes of words (sublists) with the same length.\n",
    "- Find all the anagrams for each sublist.\n",
    "- Count the total number of anagrams in each sublist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# =============================================================================\n",
    "def get_wordlist(data_path):\n",
    "    \"\"\"\n",
    "    Returns a clean, sorted list of unique lowercase English words read in from\n",
    "    the given data file located at the given path.\n",
    "    \"\"\"\n",
    "    return sorted(list(set([line.rstrip().lower()\n",
    "                            for line in open(data_path, 'r')])))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def signature(word):\n",
    "    \"\"\"\n",
    "    Returns the signature of a given word, where the signature is an ordered\n",
    "    arrangement of the individual characters of the word, joined to create a\n",
    "    single string.\n",
    "    \"\"\"\n",
    "    return ''.join(sorted(word))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def anagrams_fast(word):\n",
    "    \"\"\"\n",
    "    Finds the signature of the given word and returns a list of all the\n",
    "    anagrams for that word by a simple O(1) dictionary lookup.\n",
    "    \"\"\"\n",
    "    return words_bysignature[signature(word)]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # main()\n",
    "    \n",
    "    # Set the path for the source list of English words.\n",
    "    data_path = '#python-practice/data/web2'\n",
    "\n",
    "    # Get a clean, sorted version of unique lowercase English words.\n",
    "    wordlist = get_data(data_path)\n",
    "\n",
    "    # Buld a dictionary of words indexed by signature, where the key is the \n",
    "    # signature of every word in the clean list of English words (wordlist)\n",
    "    # and the value is a list of all the words that share the same signature.\n",
    "    words_bysignature = collections.defaultdict(list)\n",
    "\n",
    "    for word in wordlist:\n",
    "        words_bysignature[signature(word)].append(word)\n",
    "\n",
    "    # Buld a dictionary of words indexed by word length, where the key is the \n",
    "    # length of every word in the clean list of English words (wordlist)\n",
    "    # and the value is a list of all words that have the same length.\n",
    "    words_bylength = collections.defaultdict(list)\n",
    "\n",
    "    for word in wordlist:\n",
    "        words_bylength[len(word)].append(word)\n",
    "\n",
    "    # Build a dictionary of anagrams by length:\n",
    "    # For each word length (as key), we want a subdictionary (as value) \n",
    "    # containing every word of the same length (as subkey) and a list of \n",
    "    # all anagrams of that word (as subvalue).\n",
    "    # For example, {1: {}, 2: {'ab': ['ab', 'ba'], ...}, 3: {'aal': [...], ...\n",
    "    anagrams_bylength = {}\n",
    "\n",
    "    for length,words in words_bylength.items():\n",
    "        anagrams_bylength[length] = \\\n",
    "        {word:anagrams_fast(word) for word in words \n",
    "         if len(anagrams_fast(word)) > 1}\n",
    "        \n",
    "    # To know how many anagrams each word has, create another dictionary of \n",
    "    # anagrams by length:\n",
    "    # For each word length (as key), we want a subdictionary (as value) \n",
    "    # containing every word of the same length (as subkey) and the length \n",
    "    # of the list of all anagrams of that word minus 1 (so we don't count\n",
    "    # the word being anagrammed) (as subvalue).\n",
    "    # For example, {1: {}, 2: {'ab': 1, 'ad': 1, ...}, 3: {'aal': 1, ...\n",
    "    anagrams_bylength_wordcount = {}\n",
    "\n",
    "    for length,words in words_bylength.items():\n",
    "        anagrams_bylength_wordcount[length] = \\\n",
    "        {word:len(anagrams_fast(word))-1 for word in words\n",
    "         if len(anagrams_fast(word)) > 1}\n",
    "        \n",
    "    # To count the total number of anagrams in each class, create another\n",
    "    # dictionary of the total number of anagrams by length:\n",
    "    # For each word length (as key), we want the total number of anagrams\n",
    "    # as value. Notice that we need to divide the sum by 2 so we don't \n",
    "    # count each anagram twice.\n",
    "    # For example, {1: 0.0, 2: 40.0, 3: 554.0, 5: 4247.0, ...}\n",
    "    anagrams_bylength_classcount = {}\n",
    "\n",
    "    for length,words in words_bylength.items():\n",
    "        anagrams_bylength_classcount[length] = \\\n",
    "        sum(len(anagrams_fast(word)) - 1 for word in words \n",
    "            if len(anagrams_fast(word)) > 1) / 2\n",
    "\n",
    "    # Find anagrams of a given word by a simple dictionary lookup.\n",
    "    # word = 'listen'\n",
    "    # print(anagrams_fast(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0,\n",
       " 2: 40.0,\n",
       " 3: 554.0,\n",
       " 5: 4247.0,\n",
       " 4: 2780.0,\n",
       " 8: 3097.0,\n",
       " 7: 4220.0,\n",
       " 9: 2100.0,\n",
       " 6: 5153.0,\n",
       " 11: 584.0,\n",
       " 10: 1168.0,\n",
       " 12: 288.0,\n",
       " 14: 70.0,\n",
       " 16: 35.0,\n",
       " 15: 49.0,\n",
       " 20: 3.0,\n",
       " 19: 7.0,\n",
       " 17: 22.0,\n",
       " 13: 137.0,\n",
       " 18: 10.0,\n",
       " 21: 4.0,\n",
       " 22: 2.0,\n",
       " 23: 0.0,\n",
       " 24: 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams_bylength_classcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word length with the most anagrams is 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the longest word with anagrams, of length 22, has 2 anagrams. These are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cholecystoduodenostomy': 1,\n",
       " 'duodenocholecystostomy': 1,\n",
       " 'hydropneumopericardium': 1,\n",
       " 'pneumohydropericardium': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams_bylength_wordcount[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cholecystoduodenostomy': ['cholecystoduodenostomy',\n",
       "  'duodenocholecystostomy'],\n",
       " 'duodenocholecystostomy': ['cholecystoduodenostomy',\n",
       "  'duodenocholecystostomy'],\n",
       " 'hydropneumopericardium': ['hydropneumopericardium',\n",
       "  'pneumohydropericardium'],\n",
       " 'pneumohydropericardium': ['hydropneumopericardium',\n",
       "  'pneumohydropericardium']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams_bylength[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
