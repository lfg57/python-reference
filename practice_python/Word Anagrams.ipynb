{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Anagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to **find anagrams in the dictionary of English words**. Two words are anagrams of each other if their letters can be rearranged to turn one word into the other. For example, \"listen\" and \"silent\" are anagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals:**\n",
    "\n",
    "1. Load a list of English words into a Python list.\n",
    "2. Create a Python dictionary of anagrams, indexed by anagrammed word.\n",
    "3. Group dictionary words by their length and then find the total number of anagrams in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the English Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading a list of English words into Python. The data file is called `web2` and it should be located in the `../data/` folder. The file contains a list of words from *Webster's Second International Dictionary (1934)*. The 1934 copyright has lapsed and this file is included in Unix and OS X at `/usr/share/dict/web2)` as a reference word list for various uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    }
   ],
   "source": [
    "words = open('practice_python/data/web2', 'r').readlines()\n",
    "words = [line.rstrip() for line in words]  # Remove '\\n'\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same in just one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'Aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'Aaron']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [line.rstrip() for line in open('practice_python/data/web2', 'r')]\n",
    "\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also convert all the words to lowercase since we don't need capitalized words in anagrams. We can open the file, read in its contents, remove newline characters, and change case in just one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [line.rstrip().lower() for line in open('practice_python/data/web2', 'r')]\n",
    "\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the word list has duplicates, such as the terms 'A' and 'a' which now both appear as 'a' after changing the terms to lowercase. To remove duplicates, convert the list to a set and then convert back to a list. In this process, the set conversion loses the alphabetical ordering of the terms, so we also need to sort the resulting list of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_unique = sorted(list(set(words)))\n",
    "\n",
    "print(len(words_unique))\n",
    "words_unique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can open the file, read in its contents, remove newline characters, change the terms to lowercase, and remove duplicates *in a single step*:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_unique = sorted(list(set([line.rstrip().lower() for line in open('practice_python/data/web2', 'r')])))\n",
    "\n",
    "print(len(words_unique))\n",
    "words_unique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can write a nice function** to accomplish the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'practice_python/data/web2'\n",
    "\n",
    "# =============================================================================\n",
    "def get_wordlist(data_path):\n",
    "    \"\"\"\n",
    "    Returns a clean, sorted list of unique lowercase English words read in from\n",
    "    the given data file located at the given path.\n",
    "    \"\"\"\n",
    "    return sorted(list(set([line.rstrip().lower()\n",
    "                            for line in open(data_path, 'r')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_unique = get_wordlist(data_path)\n",
    "\n",
    "print(len(words_unique))\n",
    "words_unique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
